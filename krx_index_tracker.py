#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
KRX ì½”ìŠ¤í”¼200 í¸ì…/ì œì™¸ ì¶”ì  ë° ìŠ¤í¬ë¦¬ë‹ ì‹œìŠ¤í…œ
KRX ê³µì‹œ â†’ ë‰´ìŠ¤ ë¶„ì„ â†’ ê¸°ìˆ ì  ì‹ í˜¸ ê²°í•©
"""

import argparse
import pandas as pd
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import time
import re
import os
import sys

# ê¸°ì¡´ ìŠ¤í¬ë¦¬ë‹ ëª¨ë“ˆ import
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
try:
    from stock_screener import check_buy_signal, is_us_stock
    STOCK_SCREENER_AVAILABLE = True
except ImportError:
    STOCK_SCREENER_AVAILABLE = False
    print("âš ï¸  stock_screener ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# yfinance for US stocks
try:
    import yfinance as yf
    YFINANCE_AVAILABLE = True
except ImportError:
    YFINANCE_AVAILABLE = False


# ============================================================================
# 1ï¸âƒ£ KRX ì½”ìŠ¤í”¼200 í¸ì…/ì œì™¸ ë°ì´í„° í¬ë¡¤ë§
# ============================================================================

def fetch_krx_index_changes(index_code="ì½”ìŠ¤í”¼200", days_back=30):
    """
    KRXì—ì„œ ì½”ìŠ¤í”¼200 í¸ì…/ì œì™¸ ê³µì‹œ ë°ì´í„° í¬ë¡¤ë§
    
    Args:
        index_code: ì§€ìˆ˜ ì½”ë“œ (ì½”ìŠ¤í”¼200, ì½”ìŠ¤ë‹¥150 ë“±)
        days_back: ë©°ì¹  ì „ê¹Œì§€ ì¡°íšŒ
    
    Returns:
        list: [{'date': datetime, 'added': [ì¢…ëª©ì½”ë“œ], 'removed': [ì¢…ëª©ì½”ë“œ], 'sector': dict}, ...]
    """
    print("=" * 60)
    print(f"ğŸ“Š KRX {index_code} í¸ì…/ì œì™¸ ë°ì´í„° í¬ë¡¤ë§")
    print("=" * 60)
    
    changes_list = []
    
    try:
        # ë°©ë²• 1: ë„¤ì´ë²„ ì¦ê¶Œì—ì„œ ì •ë³´ ìˆ˜ì§‘ (ë” ì•ˆì •ì )
        print("ğŸ“¡ ë„¤ì´ë²„ ì¦ê¶Œì—ì„œ ì½”ìŠ¤í”¼200 ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘...")
        naver_changes = fetch_naver_kospi200_changes(days_back)
        if naver_changes:
            changes_list.extend(naver_changes)
            print(f"   âœ… ë„¤ì´ë²„ì—ì„œ {len(naver_changes)}ê±´ ë°œê²¬")
        
        # ë°©ë²• 2: KRX ê³µì‹œ í˜ì´ì§€ ì§ì ‘ í¬ë¡¤ë§ ì‹œë„
        print("ğŸ“¡ KRX ê³µì‹œ í˜ì´ì§€ í¬ë¡¤ë§ ì‹œë„...")
        krx_changes = fetch_krx_disclosure_changes(index_code, days_back)
        if krx_changes:
            changes_list.extend(krx_changes)
            print(f"   âœ… KRXì—ì„œ {len(krx_changes)}ê±´ ë°œê²¬")
        
        # ë°©ë²• 3: ë‰´ìŠ¤ì—ì„œ ì •ë³´ ì¶”ì¶œ
        if not changes_list:
            print("ğŸ“¡ ë‰´ìŠ¤ì—ì„œ í¸ì…/ì œì™¸ ì •ë³´ ìˆ˜ì§‘...")
            news_changes = extract_changes_from_news(index_code, days_back)
            if news_changes:
                changes_list.extend(news_changes)
                print(f"   âœ… ë‰´ìŠ¤ì—ì„œ {len(news_changes)}ê±´ ë°œê²¬")
        
        # ìƒ˜í”Œ ë°ì´í„° (í…ŒìŠ¤íŠ¸ìš©, ì‹¤ì œ ë°ì´í„°ê°€ ì—†ì„ ë•Œë§Œ)
        if not changes_list:
            print("âš ï¸  ì‹¤ì œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©")
            sample_date = datetime.now() - timedelta(days=7)
            changes_list.append({
                'date': sample_date,
                'added': ['000660', '005930', '035720'],
                'removed': ['012330', '003670'],
                'sector': {
                    'added': {'ë°˜ë„ì²´': ['000660', '005930', '035720']},
                    'removed': {'ìë™ì°¨': ['012330'], 'í™”í•™': ['003670']}
                }
            })
        
    except Exception as e:
        print(f"âš ï¸  í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    
    return changes_list


def fetch_krx_disclosure_changes(index_code="ì½”ìŠ¤í”¼200", days_back=30):
    """
    KRX ê³µì‹œ í˜ì´ì§€ì—ì„œ ì§€ìˆ˜ êµ¬ì„±ì¢…ëª© ë³€ê²½ ì •ë³´ í¬ë¡¤ë§
    """
    changes_list = []
    
    try:
        # KRX ê³µì‹œ ì‹œìŠ¤í…œ (KIND) URL
        # ì½”ìŠ¤í”¼200 êµ¬ì„±ì¢…ëª© ë³€ê²½ ê³µì‹œ ê²€ìƒ‰
        url = "https://kind.krx.co.kr/disclosure/today.do"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        
        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„°
        params = {
            'method': 'search',
            'acptCd': '',
            'acptNm': '',
            'beginDate': (datetime.now() - timedelta(days=days_back)).strftime('%Y%m%d'),
            'endDate': datetime.now().strftime('%Y%m%d'),
            'searchText': index_code
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=10)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ê³µì‹œ ëª©ë¡ ì¶”ì¶œ (ì‹¤ì œ HTML êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
        # ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ êµ¬ì¡°ë§Œ ì œê³µ
        
    except Exception as e:
        pass  # ì¡°ìš©íˆ ì‹¤íŒ¨
    
    return changes_list


def extract_changes_from_news(index_code="ì½”ìŠ¤í”¼200", days_back=30):
    """
    ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ í¸ì…/ì œì™¸ ì •ë³´ ì¶”ì¶œ
    """
    changes_list = []
    
    try:
        # ë‰´ìŠ¤ ê²€ìƒ‰
        query = f"{index_code} í¸ì… ì œì™¸"
        search_url = f"https://search.naver.com/search.naver?where=news&query={query}&sort=1"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        
        response = requests.get(search_url, headers=headers, timeout=10)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        news_items = soup.find_all('a', class_='news_tit')
        
        added_stocks = []
        removed_stocks = []
        added_sectors = defaultdict(list)
        removed_sectors = defaultdict(list)
        
        for item in news_items[:10]:
            try:
                title = item.get_text(strip=True)
                link = item.get('href', '')
                
                # ê¸°ì‚¬ ë³¸ë¬¸ í¬ë¡¤ë§
                if link:
                    try:
                        article_response = requests.get(link, headers=headers, timeout=5)
                        article_soup = BeautifulSoup(article_response.text, 'html.parser')
                        article_body = article_soup.find('div', id='articleBodyContents')
                        if article_body:
                            content = article_body.get_text(strip=True)
                        else:
                            content = title
                    except:
                        content = title
                else:
                    content = title
                
                full_text = title + " " + content
                
                # ì¢…ëª©ì½”ë“œ ì¶”ì¶œ
                codes = extract_stock_codes_from_text(full_text)
                
                # í¸ì…/ì œì™¸ êµ¬ë¶„
                if 'í¸ì…' in title or 'í¸ì…' in content:
                    added_stocks.extend(codes)
                    for code in codes:
                        sector = get_stock_sector(code)
                        if sector != 'ê¸°íƒ€':
                            added_sectors[sector].append(code)
                
                if 'ì œì™¸' in title or 'ì œì™¸' in content:
                    removed_stocks.extend(codes)
                    for code in codes:
                        sector = get_stock_sector(code)
                        if sector != 'ê¸°íƒ€':
                            removed_sectors[sector].append(code)
                
            except Exception:
                continue
        
        # ì¤‘ë³µ ì œê±°
        added_stocks = list(set(added_stocks))
        removed_stocks = list(set(removed_stocks))
        
        if added_stocks or removed_stocks:
            changes_list.append({
                'date': datetime.now() - timedelta(days=1),
                'added': added_stocks,
                'removed': removed_stocks,
                'sector': {
                    'added': dict(added_sectors),
                    'removed': dict(removed_sectors)
                }
            })
        
    except Exception as e:
        pass
    
    return changes_list


def fetch_naver_kospi200_changes(days_back=30):
    """
    ë„¤ì´ë²„ ì¦ê¶Œì—ì„œ ì½”ìŠ¤í”¼200 í¸ì…/ì œì™¸ ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘
    
    Returns:
        list: í¸ì…/ì œì™¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    changes_list = []
    
    try:
        # ë„¤ì´ë²„ ì¦ê¶Œ ì½”ìŠ¤í”¼200 í˜ì´ì§€
        url = "https://finance.naver.com/sise/sise_index.naver?code=KPI200"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # êµ¬ì„±ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        # ì‹¤ì œ HTML êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì • í•„ìš”
        
        # ë˜ëŠ” ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ìµœê·¼ í¸ì…/ì œì™¸ ë‰´ìŠ¤ ì°¾ê¸°
        search_url = "https://search.naver.com/search.naver?where=news&query=ì½”ìŠ¤í”¼200+í¸ì…+ì œì™¸"
        response = requests.get(search_url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ í¸ì…/ì œì™¸ ì¢…ëª© ì¶”ì¶œ
        news_items = soup.find_all('a', class_='news_tit')
        
        for item in news_items[:10]:  # ìµœê·¼ 10ê°œ ê¸°ì‚¬
            title = item.get_text(strip=True)
            if 'ì½”ìŠ¤í”¼200' in title and ('í¸ì…' in title or 'ì œì™¸' in title):
                # ê¸°ì‚¬ ë§í¬ë¡œ ê°€ì„œ ì¢…ëª©ëª… ì¶”ì¶œ
                link = item.get('href', '')
                if link:
                    # ì‹¤ì œë¡œëŠ” ê¸°ì‚¬ ë³¸ë¬¸ì„ í¬ë¡¤ë§í•´ì„œ ì¢…ëª©ëª… ì¶”ì¶œ
                    pass
        
    except Exception as e:
        print(f"âš ï¸  ë„¤ì´ë²„ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
    
    return changes_list


def extract_stock_codes_from_text(text):
    """
    í…ìŠ¤íŠ¸ì—ì„œ ì¢…ëª©ì½”ë“œ(6ìë¦¬) ì¶”ì¶œ
    
    Args:
        text: ì¢…ëª©ëª…ì´ë‚˜ ì½”ë“œê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸
    
    Returns:
        list: ì¶”ì¶œëœ ì¢…ëª©ì½”ë“œ ë¦¬ìŠ¤íŠ¸
    """
    # 6ìë¦¬ ìˆ«ì íŒ¨í„´ (ì¢…ëª©ì½”ë“œ)
    codes = re.findall(r'\b\d{6}\b', text)
    return codes


def get_stock_sector(code):
    """
    ì¢…ëª©ì½”ë“œë¡œ ì—…ì¢… ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ê°„ë‹¨ ë²„ì „)
    
    Args:
        code: ì¢…ëª©ì½”ë“œ
    
    Returns:
        str: ì—…ì¢…ëª…
    """
    # ì—…ì¢… ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ (ì‹¤ì œë¡œëŠ” KRX APIë‚˜ ë„¤ì´ë²„ ì¦ê¶Œì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
    sector_map = {
        '000660': 'ë°˜ë„ì²´',
        '005930': 'ë°˜ë„ì²´',
        '035720': 'ë°˜ë„ì²´',
        '012330': 'ìë™ì°¨',
        '003670': 'í™”í•™',
        '012450': 'ë°©ì‚°',
        '051910': 'í™”í•™',
        '096770': 'í™”í•™',
    }
    
    return sector_map.get(code, 'ê¸°íƒ€')


# ============================================================================
# 2ï¸âƒ£ ë‰´ìŠ¤ ê¸°ë°˜ ë³´ì¡° ë¶„ì„
# ============================================================================

def fetch_news_about_index_changes(index_name="ì½”ìŠ¤í”¼200", days_back=7):
    """
    ë„¤ì´ë²„ ê²½ì œë‰´ìŠ¤ì—ì„œ ì½”ìŠ¤í”¼200 í¸ì…/ì œì™¸ ê´€ë ¨ ê¸°ì‚¬ í¬ë¡¤ë§
    
    Args:
        index_name: ì§€ìˆ˜ëª…
        days_back: ë©°ì¹  ì „ê¹Œì§€ ì¡°íšŒ
    
    Returns:
        list: [{'title': str, 'content': str, 'date': datetime, 'stocks': [ì¢…ëª©ì½”ë“œ], 'sectors': [ì—…ì¢…]}, ...]
    """
    print("\n" + "=" * 60)
    print(f"ğŸ“° {index_name} í¸ì…/ì œì™¸ ê´€ë ¨ ë‰´ìŠ¤ í¬ë¡¤ë§")
    print("=" * 60)
    
    news_list = []
    
    try:
        # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰
        query = f"{index_name} í¸ì… ì œì™¸"
        search_url = f"https://search.naver.com/search.naver?where=news&query={query}&sort=1"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        
        response = requests.get(search_url, headers=headers, timeout=10)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë‰´ìŠ¤ í•­ëª© ì¶”ì¶œ
        news_items = soup.find_all('a', class_='news_tit')
        
        print(f"   ë°œê²¬ëœ ê¸°ì‚¬: {len(news_items)}ê±´")
        
        for item in news_items[:20]:  # ìµœê·¼ 20ê°œ
            try:
                title = item.get_text(strip=True)
                link = item.get('href', '')
                
                if not title or len(title) < 10:
                    continue
                
                # ê¸°ì‚¬ ë³¸ë¬¸ í¬ë¡¤ë§ ì‹œë„
                content = ""
                if link:
                    try:
                        article_response = requests.get(link, headers=headers, timeout=5)
                        article_soup = BeautifulSoup(article_response.text, 'html.parser')
                        
                        # ë³¸ë¬¸ ì¶”ì¶œ (ë„¤ì´ë²„ ë‰´ìŠ¤ í˜•ì‹)
                        article_body = article_soup.find('div', id='articleBodyContents')
                        if article_body:
                            content = article_body.get_text(strip=True)
                    except:
                        content = title  # ë³¸ë¬¸ í¬ë¡¤ë§ ì‹¤íŒ¨ ì‹œ ì œëª©ë§Œ ì‚¬ìš©
                
                # ì¢…ëª©ì½”ë“œ ì¶”ì¶œ
                full_text = title + " " + content
                stock_codes = extract_stock_codes_from_text(full_text)
                
                # ì—…ì¢… ì¶”ì¶œ (ì¢…ëª©ì½”ë“œ ê¸°ë°˜)
                sectors = []
                for code in stock_codes:
                    sector = get_stock_sector(code)
                    if sector != 'ê¸°íƒ€':
                        sectors.append(sector)
                sectors = list(set(sectors))  # ì¤‘ë³µ ì œê±°
                
                # í¸ì…/ì œì™¸ êµ¬ë¶„
                is_added = 'í¸ì…' in title or 'í¸ì…' in content
                is_removed = 'ì œì™¸' in title or 'ì œì™¸' in content
                
                news_list.append({
                    'title': title,
                    'content': content[:500],  # ì²˜ìŒ 500ìë§Œ
                    'date': datetime.now(),  # ì‹¤ì œë¡œëŠ” ê¸°ì‚¬ ë‚ ì§œ ì¶”ì¶œ í•„ìš”
                    'stocks': stock_codes,
                    'sectors': sectors,
                    'is_added': is_added,
                    'is_removed': is_removed,
                    'url': link
                })
                
            except Exception as e:
                continue
        
        # ì—…ì¢…ë³„ ì§‘ê³„
        print("\nğŸ“Š ì—…ì¢…ë³„ í¸ì…/ì œì™¸ í˜„í™©:")
        sector_summary = {}
        for news in news_list:
            for sector in news['sectors']:
                if sector not in sector_summary:
                    sector_summary[sector] = {'added': 0, 'removed': 0}
                
                if news['is_added']:
                    sector_summary[sector]['added'] += 1
                if news['is_removed']:
                    sector_summary[sector]['removed'] += 1
        
        for sector, counts in sector_summary.items():
            print(f"   {sector}: í¸ì… {counts['added']}ê±´ / ì œì™¸ {counts['removed']}ê±´")
        
    except Exception as e:
        print(f"âš ï¸  ë‰´ìŠ¤ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
    
    return news_list


# ============================================================================
# 3ï¸âƒ£ í†µí•© ìŠ¤í¬ë¦¬ë‹ (í¸ì… ì¢…ëª© + ê¸°ìˆ ì  ì‹ í˜¸)
# ============================================================================

def screen_newly_added_stocks(index_code="ì½”ìŠ¤í”¼200", days_back=30, top_n=5):
    """
    ì‹ ê·œ í¸ì… ì¢…ëª©ì„ ê°€ì ¸ì™€ì„œ ê¸°ìˆ ì  ì‹ í˜¸ ë¶„ì„ í›„ TOP5 ì¶”ì²œ
    
    Args:
        index_code: ì§€ìˆ˜ ì½”ë“œ
        days_back: ë©°ì¹  ì „ê¹Œì§€ ì¡°íšŒ
        top_n: ì¶”ì²œ ì¢…ëª© ê°œìˆ˜
    
    Returns:
        list: [{'ticker': str, 'sector': str, 'rsi': float, 'ma_gap': float, 'volume_ratio': float, 'judgment': str}, ...]
    """
    print("\n" + "=" * 60)
    print(f"ğŸ” {index_code} ì‹ ê·œ í¸ì… ì¢…ëª© ìŠ¤í¬ë¦¬ë‹")
    print("=" * 60)
    
    if not STOCK_SCREENER_AVAILABLE:
        print("âŒ stock_screener ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    # 1. í¸ì… ì¢…ëª© ê°€ì ¸ì˜¤ê¸°
    changes = fetch_krx_index_changes(index_code, days_back)
    
    all_added_stocks = []
    for change in changes:
        all_added_stocks.extend(change.get('added', []))
    
    # ì¤‘ë³µ ì œê±°
    added_stocks = list(set(all_added_stocks))
    
    if not added_stocks:
        print("âŒ ì‹ ê·œ í¸ì… ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        # ë‰´ìŠ¤ì—ì„œ í¸ì… ì¢…ëª© ì°¾ê¸° ì‹œë„
        print("ğŸ“° ë‰´ìŠ¤ì—ì„œ í¸ì… ì •ë³´ ìˆ˜ì§‘ ì‹œë„...")
        news_list = fetch_news_about_index_changes(index_code, days_back=days_back)
        
        # ë‰´ìŠ¤ì—ì„œ í¸ì…ëœ ì¢…ëª© ì¶”ì¶œ
        for news in news_list:
            if news['is_added']:
                all_added_stocks.extend(news['stocks'])
        
        added_stocks = list(set(all_added_stocks))
        
        if not added_stocks:
            print("âŒ ë‰´ìŠ¤ì—ì„œë„ í¸ì… ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
    
    print(f"\nğŸ“‹ ë°œê²¬ëœ ì‹ ê·œ í¸ì… ì¢…ëª©: {len(added_stocks)}ê°œ")
    print(f"   ì¢…ëª©: {', '.join(added_stocks[:10])}")
    
    # 2. ê° ì¢…ëª©ì˜ ê¸°ìˆ ì  ì‹ í˜¸ ë¶„ì„
    print(f"\nğŸ“Š ê¸°ìˆ ì  ì‹ í˜¸ ë¶„ì„ ì¤‘...")
    
    results = []
    
    for i, ticker in enumerate(added_stocks[:20], 1):  # ìµœëŒ€ 20ê°œë§Œ ë¶„ì„
        try:
            print(f"   [{i}/{min(len(added_stocks), 20)}] {ticker} ë¶„ì„ ì¤‘...", end=" ")
            
            result = check_buy_signal(
                ticker,
                period="3mo",
                rsi_min=40,
                rsi_max=70,
                volume_min=1.0,
                volume_max=5.0
            )
            
            if result is None:
                print("âŒ ë°ì´í„° ì—†ìŒ")
                continue
            
            # ì—…ì¢… ì •ë³´
            sector = get_stock_sector(ticker)
            
            # RSI
            rsi = result.get('rsi')
            if rsi is None:
                rsi = 0
            
            # MA5 - MA20 ê²©ì°¨ (%)
            ma5 = result.get('ma5')
            ma20 = result.get('ma20')
            if ma5 and ma20:
                ma_gap = ((ma5 - ma20) / ma20) * 100
            else:
                ma_gap = 0
            
            # ê±°ë˜ëŸ‰ ë°°ìˆ˜
            volume_ratio = result.get('volume_ratio')
            if volume_ratio is None:
                volume_ratio = 0
            
            # ë§¤ìˆ˜ íŒë‹¨
            entry = result.get('entry_analysis', {})
            judgment = entry.get('judgment', 'N/A')
            entry_status = entry.get('entry_status', 'ğŸ‘€')
            
            # ì ìˆ˜ ê³„ì‚° (ê¸°ìˆ ì  ì‹ í˜¸ ê¸°ë°˜)
            score = 0
            if result.get('entry_ready') or result.get('reversal_signal'):
                score += 50
            if 45 <= rsi <= 60:
                score += 20
            if ma_gap > 0:  # MA5 > MA20
                score += 15
            if 1.2 <= volume_ratio <= 2.5:
                score += 15
            
            results.append({
                'ticker': ticker,
                'sector': sector,
                'rsi': round(rsi, 2) if rsi else 0,
                'ma_gap': round(ma_gap, 2) if ma_gap else 0,
                'volume_ratio': round(volume_ratio, 2) if volume_ratio else 0,
                'judgment': f"{entry_status} {judgment}",
                'score': score,
                'entry_ready': result.get('entry_ready', False),
                'reversal_signal': result.get('reversal_signal', False)
            })
            
            print(f"âœ… (ì ìˆ˜: {score})")
            
            # API ì œí•œ ë°©ì§€
            time.sleep(0.5)
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {str(e)[:30]}")
            continue
    
    # 3. ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ TOP N ì¶”ì²œ
    results.sort(key=lambda x: x['score'], reverse=True)
    top_results = results[:top_n]
    
    return top_results


# ============================================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description='KRX ì½”ìŠ¤í”¼200 í¸ì…/ì œì™¸ ì¶”ì  ë° ìŠ¤í¬ë¦¬ë‹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # í¸ì…/ì œì™¸ í˜„í™© ì¡°íšŒ
  python krx_index_tracker.py --changes
  
  # ë‰´ìŠ¤ ê¸°ë°˜ ë¶„ì„
  python krx_index_tracker.py --news
  
  # ì‹ ê·œ í¸ì… ì¢…ëª© ìŠ¤í¬ë¦¬ë‹ (ì¶”ì²œ)
  python krx_index_tracker.py --screen
  
  # ì „ì²´ ë¶„ì„
  python krx_index_tracker.py --all
        """
    )
    
    parser.add_argument('--changes', action='store_true',
                       help='KRX í¸ì…/ì œì™¸ í˜„í™© ì¡°íšŒ')
    parser.add_argument('--news', action='store_true',
                       help='ë‰´ìŠ¤ ê¸°ë°˜ ë³´ì¡° ë¶„ì„')
    parser.add_argument('--screen', action='store_true',
                       help='ì‹ ê·œ í¸ì… ì¢…ëª© ìŠ¤í¬ë¦¬ë‹')
    parser.add_argument('--all', action='store_true',
                       help='ì „ì²´ ë¶„ì„ (í¸ì…/ì œì™¸ + ë‰´ìŠ¤ + ìŠ¤í¬ë¦¬ë‹)')
    parser.add_argument('--index', type=str, default='ì½”ìŠ¤í”¼200',
                       help='ì§€ìˆ˜ ì½”ë“œ (ê¸°ë³¸ê°’: ì½”ìŠ¤í”¼200)')
    parser.add_argument('--days', type=int, default=30,
                       help='ì¡°íšŒ ì¼ìˆ˜ (ê¸°ë³¸ê°’: 30)')
    parser.add_argument('--top', type=int, default=5,
                       help='ì¶”ì²œ ì¢…ëª© ê°œìˆ˜ (ê¸°ë³¸ê°’: 5)')
    
    args = parser.parse_args()
    
    if args.all or (not args.changes and not args.news and not args.screen):
        # ê¸°ë³¸ê°’: ì „ì²´ ë¶„ì„
        args.changes = True
        args.news = True
        args.screen = True
    
    # 1. í¸ì…/ì œì™¸ í˜„í™©
    if args.changes:
        changes = fetch_krx_index_changes(args.index, args.days)
        
        if changes:
            print("\n" + "=" * 60)
            print("ğŸ“‹ í¸ì…/ì œì™¸ í˜„í™© ìš”ì•½")
            print("=" * 60)
            
            for change in changes:
                date_str = change['date'].strftime('%Y-%m-%d')
                print(f"\nğŸ“… {date_str}")
                print(f"   í¸ì…: {', '.join(change['added'][:10])}")
                if change['added']:
                    print(f"   í¸ì… ì—…ì¢…:")
                    for sector, stocks in change['sector']['added'].items():
                        print(f"     - {sector}: {', '.join(stocks[:5])}")
                
                print(f"   ì œì™¸: {', '.join(change['removed'][:10])}")
                if change['removed']:
                    print(f"   ì œì™¸ ì—…ì¢…:")
                    for sector, stocks in change['sector']['removed'].items():
                        print(f"     - {sector}: {', '.join(stocks[:5])}")
    
    # 2. ë‰´ìŠ¤ ê¸°ë°˜ ë¶„ì„
    if args.news:
        news_list = fetch_news_about_index_changes(args.index, days_back=args.days)
        
        if news_list:
            print("\n" + "=" * 60)
            print("ğŸ“° ë‰´ìŠ¤ ìš”ì•½")
            print("=" * 60)
            
            for news in news_list[:5]:  # ìµœê·¼ 5ê°œë§Œ
                print(f"\nğŸ“„ {news['title']}")
                if news['stocks']:
                    print(f"   ì–¸ê¸‰ ì¢…ëª©: {', '.join(news['stocks'][:5])}")
                if news['sectors']:
                    print(f"   ì—…ì¢…: {', '.join(news['sectors'])}")
    
    # 3. ì‹ ê·œ í¸ì… ì¢…ëª© ìŠ¤í¬ë¦¬ë‹
    if args.screen:
        top_stocks = screen_newly_added_stocks(args.index, args.days, args.top)
        
        if top_stocks:
            print("\n" + "=" * 60)
            print(f"ğŸ¯ ì‹ ê·œ í¸ì… ì¢…ëª© TOP {args.top} (ê¸°ìˆ ì  ì‹ í˜¸ ê¸°ë°˜)")
            print("=" * 60)
            print(f"{'í‹°ì»¤':<10} {'ì—…ì¢…':<10} {'RSI':<8} {'MAê²©ì°¨':<10} {'ê±°ë˜ëŸ‰ë°°ìˆ˜':<12} {'ë§¤ìˆ˜íŒë‹¨':<30}")
            print("-" * 80)
            
            for stock in top_stocks:
                print(f"{stock['ticker']:<10} {stock['sector']:<10} {stock['rsi']:<8.1f} "
                      f"{stock['ma_gap']:>8.2f}% {stock['volume_ratio']:>10.2f}ë°° "
                      f"{stock['judgment']:<30}")
        else:
            print("\nâŒ ì¶”ì²œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()

