#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Crude oil sentiment pulse checker tuned for Devon Energy (DVN).

Pipeline
--------
1. Crawl selected energy news sources and retain links containing oil-related
   keywords.
2. Fetch each article, count bearish (supply surplus, weak demand, strong USD)
   and bullish (supply disruption, geopolitical risk) signals.
3. Pull quick market snapshots (DXY, WTI front-month) from Yahoo Finance.
4. Blend keyword scores with market data to classify today's crude tone:
      - score <= -2 : downside pressure
      - -1 <= score <= 1 : neutral / noisy
      - score >= 2 : tightening / upside risk
5. Translate the crude outlook into a DVN trading stance hint.

Run
---
    python crude_oil_sentiment.py
    python crude_oil_sentiment.py --max-articles 20 --json

Remarks
-------
- Network access is required for live crawling and market data.
- Designed for fast situational awareness, not investment advice.
"""

from __future__ import annotations

import argparse
import json
import math
import re
from dataclasses import dataclass, asdict
from datetime import datetime, timezone
from typing import Dict, Iterable, List, Optional, Tuple

import requests
from bs4 import BeautifulSoup
import xml.etree.ElementTree as ET

# ---------------------------------------------------------------------------
# Macro context (static primer printed in output header)
# ---------------------------------------------------------------------------

MACRO_CONTEXT = (
    "2025 ìœ ê°€ëŠ” ê³µê¸‰ ìš°ìœ„ ê¸°ì¡°ê°€ ê¸°ë³¸ê°’ì…ë‹ˆë‹¤. IEA/EIA ëª¨ë‘ ë¹„OPEC ì¦ì‚°(ë¯¸êµ­Â·ë¸Œë¼ì§ˆÂ·ê°€ì´ì•„ë‚˜)ì´ "
    "ìˆ˜ìš” ì¦ê°€ë¥¼ ìƒíšŒí•  ê²ƒìœ¼ë¡œ ë³´ë©°, OPEC+ ë˜í•œ ì™„ì „í•œ ê°ì‚°ë³´ë‹¤ëŠ” ë¶€ë¶„ ì™„í™”ì— ê°€ê¹ìŠµë‹ˆë‹¤. "
    "ë”°ë¼ì„œ ê³µê¸‰ ì°¨ì§ˆ ë‰´ìŠ¤ê°€ ì—†ë‹¤ë©´ ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤ëŠ” 'ê°€ê²© ëˆŒë¦¼ ìœ ì§€' ìª½ì…ë‹ˆë‹¤."
)

# ---------------------------------------------------------------------------
# News sources and keyword lexicons
# ---------------------------------------------------------------------------

# (name, url, parser)
NEWS_SOURCES: List[Tuple[str, str]] = [
    ("EIA Today in Energy", "https://www.eia.gov/rss/todayinenergy.xml"),
    ("Oilprice", "https://oilprice.com/rss/main"),
    ("Reuters Commodities", "https://feeds.reuters.com/news/commodities"),
    ("BBC Business", "https://feeds.bbci.co.uk/news/business/rss.xml"),
]

HTTP_HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
    )
}

RSS_TIMEOUT = 20

# Keywords that imply bearish pressure (more supply, weaker demand, stronger USD)
SUPPLY_BEAR_KEYS = {
    "output", "production", "supply", "export", "opec", "opec+", "barrels per day",
    "inventory build", "stock build", "storage build", "sanction relief",
    "us shale", "rig count", "capacity increase"
}

DEMAND_BEAR_KEYS = {
    "weak demand", "sluggish demand", "slowdown", "pmi", "factory activity",
    "manufacturing contraction", "economic growth", "recession",
    "china demand", "jet fuel demand", "industrial slowdown", "consumption drop"
}

USD_BEAR_KEYS = {
    "dollar index", "dxy", "strong dollar", "usd strength", "fed", "interest rate",
    "rate hike", "higher for longer", "treasury yields"
}

# Keywords that imply bullish (tightening) forces
SUPPLY_BULL_KEYS = {
    "disruption", "outage", "pipeline shut", "supply cut", "unplanned outage",
    "geopolitical risk", "strike", "houthi", "strait", "hurricane", "force majeure",
    "attack", "sanction tightening", "production halt"
}

DEMAND_BULL_KEYS = {
    "demand recovery", "rebound in demand", "travel demand", "jet fuel surge",
    "china stimulus", "manufacturing rebound"
}

# Extra weight if a bullish keyword appears in these "special" outlets
SPECIAL_WEIGHT_SOURCES = ("iea.org", "opec.org", "eia.gov")
SPECIAL_WEIGHT = 2

# ---------------------------------------------------------------------------
# Market data endpoints (Yahoo Finance chart API is simple JSON)
# ---------------------------------------------------------------------------

YAHOO_DXY_URL = "https://query1.finance.yahoo.com/v8/finance/chart/DX-Y.NYB"
YAHOO_WTI_URL = "https://query1.finance.yahoo.com/v8/finance/chart/CL=F"

# ---------------------------------------------------------------------------
# Data containers
# ---------------------------------------------------------------------------


@dataclass
class ArticleSignal:
    source: str
    title: str
    url: str
    supply_bear: int
    demand_bear: int
    usd_bear: int
    supply_bull: int
    demand_bull: int

    @property
    def bearish_sum(self) -> int:
        return self.supply_bear + self.demand_bear + self.usd_bear

    @property
    def bullish_sum(self) -> int:
        return self.supply_bull + self.demand_bull

    def to_dict(self) -> Dict[str, object]:
        payload = asdict(self)
        payload["bearish_total"] = self.bearish_sum
        payload["bullish_total"] = self.bullish_sum
        return payload


@dataclass
class MarketSnapshot:
    dxy: Optional[float]
    wti: Optional[float]


@dataclass
class SentimentSummary:
    timestamp_utc: str
    supply_pressure: int
    demand_pressure: int
    usd_pressure: int
    bullish_support: int
    total_score: int
    classification: str
    dvn_playbook: str
    market: MarketSnapshot
    articles: List[ArticleSignal]

    def to_dict(self) -> Dict[str, object]:
        return {
            "timestamp_utc": self.timestamp_utc,
            "macro_context": MACRO_CONTEXT,
            "aggregate": {
                "supply_pressure": self.supply_pressure,
                "demand_pressure": self.demand_pressure,
                "usd_pressure": self.usd_pressure,
                "bullish_support": self.bullish_support,
                "total_score": self.total_score,
                "classification": self.classification,
                "dvn_playbook": self.dvn_playbook,
            },
            "market": {
                "dxy": self.market.dxy,
                "wti": self.market.wti,
            },
            "articles": [article.to_dict() for article in self.articles],
        }


# ---------------------------------------------------------------------------
# Utility functions
# ---------------------------------------------------------------------------


def fetch_html(url: str, timeout: int = RSS_TIMEOUT) -> str:
    resp = requests.get(url, timeout=timeout, headers=HTTP_HEADERS)
    resp.raise_for_status()
    return resp.text


def normalize_whitespace(text: str) -> str:
    return re.sub(r"\s+", " ", text).strip()


def contains_keyword(text_lower: str, keyword: str) -> bool:
    return keyword in text_lower


def score_text(text: str, origin_url: str) -> Tuple[int, int, int, int, int]:
    text_lower = text.lower()

    supply_bear = sum(1 for kw in SUPPLY_BEAR_KEYS if contains_keyword(text_lower, kw))
    demand_bear = sum(1 for kw in DEMAND_BEAR_KEYS if contains_keyword(text_lower, kw))
    usd_bear = sum(1 for kw in USD_BEAR_KEYS if contains_keyword(text_lower, kw))

    supply_bull = sum(1 for kw in SUPPLY_BULL_KEYS if contains_keyword(text_lower, kw))
    demand_bull = sum(1 for kw in DEMAND_BULL_KEYS if contains_keyword(text_lower, kw))

    if supply_bull or demand_bull:
        if origin_url and any(tag in origin_url for tag in SPECIAL_WEIGHT_SOURCES):
            supply_bull += SPECIAL_WEIGHT

    return supply_bear, demand_bear, usd_bear, supply_bull, demand_bull


def parse_rss_items(xml_text: str) -> List[Dict[str, str]]:
    items: List[Dict[str, str]] = []

    def _append_item(title: str, description: str, link: str) -> None:
        content = normalize_whitespace(f"{title} {description}")
        items.append(
            {
                "title": title,
                "description": description,
                "link": link,
                "content": content,
            }
        )

    try:
        root = ET.fromstring(xml_text)
        for element in root.iter():
            if element.tag.lower().endswith("item"):
                title_node = element.find("./title")
                desc_node = element.find("./description")
                link_node = element.find("./link")
                title = title_node.text.strip() if title_node is not None and title_node.text else ""
                description = (
                    desc_node.text.strip() if desc_node is not None and desc_node.text else ""
                )
                link = link_node.text.strip() if link_node is not None and link_node.text else ""
                _append_item(title, description, link)
    except ET.ParseError:
        soup = BeautifulSoup(xml_text, "html.parser")
        for item in soup.find_all("item"):
            title = item.title.get_text(strip=True) if item.title else ""
            description = item.description.get_text(" ", strip=True) if item.description else ""
            link = item.link.get_text(strip=True) if item.link else ""
            _append_item(title, description, link)

    return items


def crawl_news(max_articles: int) -> List[ArticleSignal]:
    collected: List[ArticleSignal] = []

    per_source_limit = max(5, max_articles // max(1, len(NEWS_SOURCES)))

    for source_name, source_url in NEWS_SOURCES:
        try:
            feed_text = fetch_html(source_url)
            candidates = parse_rss_items(feed_text)
        except Exception as exc:
            print(f"âš ï¸  ì†ŒìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {source_name} ({source_url}) -> {exc}")
            continue

        for item in candidates:
            if len(collected) >= max_articles:
                break
            title = item.get("title", "")
            url = item.get("link", "")
            content = item.get("content", "")

            if not url and item.get("link"):
                url = item["link"]

            if not content:
                content = normalize_whitespace(title or "")

            try:
                supply_bear, demand_bear, usd_bear, supply_bull, demand_bull = score_text(content, url)

                if not any([supply_bear, demand_bear, usd_bear, supply_bull, demand_bull]):
                    continue

                collected.append(
                    ArticleSignal(
                        source=source_name,
                        title=title,
                        url=url,
                        supply_bear=supply_bear,
                        demand_bear=demand_bear,
                        usd_bear=usd_bear,
                        supply_bull=supply_bull,
                        demand_bull=demand_bull,
                    )
                )
            except Exception as exc:
                print(f"âš ï¸  ê¸°ì‚¬ ë¶„ì„ ì‹¤íŒ¨: {title or url} ({exc})")
                continue

    return collected


def fetch_market_value(url: str) -> Optional[float]:
    try:
        raw = requests.get(url, timeout=10, headers={"User-Agent": "Mozilla/5.0"})
        raw.raise_for_status()
        payload = raw.json()
        result = payload.get("chart", {}).get("result", [])
        if not result:
            return None
        meta = result[0].get("meta", {})
        price = meta.get("regularMarketPrice") or meta.get("previousClose")
        if price is None:
            return None
        return round(float(price), 2)
    except Exception:
        return None


def build_market_snapshot() -> MarketSnapshot:
    dxy_val = fetch_market_value(YAHOO_DXY_URL)
    wti_val = fetch_market_value(YAHOO_WTI_URL)
    return MarketSnapshot(dxy=dxy_val, wti=wti_val)


def classify_sentiment(supply_pressure: int, demand_pressure: int, usd_pressure: int,
                       bullish_support: int, market: MarketSnapshot) -> Tuple[int, str]:
    bearish_total = supply_pressure + demand_pressure + usd_pressure
    total_score = bullish_support - bearish_total

    if market.dxy and market.dxy >= 102:
        total_score -= 1
    if market.wti and market.wti <= 70:
        total_score -= 1

    if total_score <= -2:
        classification = "ì˜¤ëŠ˜ì€ ìœ ê°€ í•˜ë°© ì••ë ¥"
    elif total_score >= 2:
        classification = "íƒ€ì´íŠ¸ ê°€ëŠ¥ì„± (ìƒë°© ê²½ê³„)"
    else:
        classification = "ì¤‘ë¦½ (ë‰´ìŠ¤ í˜¼ì¬)"

    return total_score, classification


def dvn_playbook(total_score: int) -> str:
    if total_score <= -2:
        return "DVNì€ ë³´ìˆ˜ì  ì ‘ê·¼. ëˆŒë¦¼ ë§¤ìˆ˜ ëŒ€ê¸° ë° í¬ì§€ì…˜ ì¶•ì†Œ ê²€í† ."
    if total_score >= 2:
        return "DVNì€ ê³µê²©ì  ìŠ¤ìœ™ ê°€ëŠ¥. ê³µê¸‰ ì°¨ì§ˆ í™•ì¸ ì‹œ ë¶„í•  ë§¤ìˆ˜."
    return "DVNì€ ê´€ë§ ë˜ëŠ” ì†Œê·œëª¨ ë¹„ì¤‘. ëª…í™•í•œ ëª¨ë©˜í…€ í™•ì¸ í•„ìš”."


def summarize(articles: List[ArticleSignal], market: MarketSnapshot) -> SentimentSummary:
    supply_pressure = sum(article.supply_bear for article in articles)
    demand_pressure = sum(article.demand_bear for article in articles)
    usd_pressure = sum(article.usd_bear for article in articles)
    bullish_support = sum(article.bullish_sum for article in articles)

    total_score, classification = classify_sentiment(
        supply_pressure,
        demand_pressure,
        usd_pressure,
        bullish_support,
        market,
    )

    playbook = dvn_playbook(total_score)

    timestamp = datetime.now(timezone.utc).replace(microsecond=0).isoformat()
    return SentimentSummary(
        timestamp_utc=timestamp,
        supply_pressure=supply_pressure,
        demand_pressure=demand_pressure,
        usd_pressure=usd_pressure,
        bullish_support=bullish_support,
        total_score=total_score,
        classification=classification,
        dvn_playbook=playbook,
        market=market,
        articles=articles,
    )


def render_text(summary: SentimentSummary) -> None:
    print("==============================================")
    print("ğŸŒ 2025 ì›ìœ  ì‹œì¥ ê¸°ë³¸ ë°°ê²½")
    print("==============================================")
    print(MACRO_CONTEXT)
    print()

    print("==============================================")
    print("ğŸ“¥ ìˆ˜ì§‘ ìš”ì•½")
    print("==============================================")
    print(f"âœ… ìˆ˜ì§‘ ì„±ê³µí•œ ê¸°ì‚¬ ê±´ìˆ˜: {len(summary.articles)}")
    for article in summary.articles:
        print(f" - {article.source}: {article.title}")
    if summary.articles:
        print()

    print("==============================================")
    print("ğŸ“Š ë‰´ìŠ¤ ê¸°ë°˜ ì‹ í˜¸ ìš”ì•½")
    print("==============================================")
    print(f"- ê³µê¸‰ ê³¼ì‰/í•´ì œ ì‹œê·¸ë„: {summary.supply_pressure} ê±´ (ìœ ê°€ í•˜ë°©)")
    print(f"- ìˆ˜ìš” ë‘”í™” ì‹œê·¸ë„: {summary.demand_pressure} ê±´ (ìœ ê°€ í•˜ë°©)")
    print(f"- ë‹¬ëŸ¬ ê°•ì„¸/ê¸ˆë¦¬ ì••ë ¥: {summary.usd_pressure} ê±´ (ìœ ê°€ í•˜ë°©)")
    print(f"- ê³µê¸‰ ì°¨ì§ˆÂ·ìˆ˜ìš” íšŒë³µ ì‹œê·¸ë„: {summary.bullish_support} ê±´ (ìœ ê°€ ìƒë°©)")
    print()
    print(f"â¡ï¸  ì¢…í•© ì ìˆ˜: {summary.total_score} â†’ {summary.classification}")
    print()

    print("==============================================")
    print("ğŸ›¢  ì‹œì¥ ìŠ¤ëƒ…ìƒ·")
    print("==============================================")
    dxy = summary.market.dxy
    wti = summary.market.wti
    print(f"- DXY (ë‹¬ëŸ¬ ì¸ë±ìŠ¤): {dxy if dxy is not None else 'N/A'}")
    print(f"- WTI ê·¼ì›”ë¬¼: {wti if wti is not None else 'N/A'}")
    if dxy and dxy >= 102:
        print("  âš ï¸  ê°•ë‹¬ëŸ¬ êµ¬ê°„ â†’ ìœ ê°€ì—ëŠ” ë¶€ë‹´ ìš”ì¸")
    if wti and wti <= 70:
        print("  âš ï¸  70ë‹¬ëŸ¬ ì´í•˜ â†’ ì¶”ê°€ í•˜ë½ ì‹œ ì…°ì¼ ë²„ì§“ ì²´í¬")
    print()

    print("==============================================")
    print("ğŸ“ˆ DVN ìŠ¤ìœ™ ì „ëµ ê°€ì´ë“œ")
    print("==============================================")
    print(summary.dvn_playbook)
    print()

    if summary.articles:
        print("==============================================")
        print("ğŸ“° ì°¸ê³  ê¸°ì‚¬ (ìƒì„¸ ë“í‘œ)")
        print("==============================================")
        for idx, article in enumerate(summary.articles, 1):
            print(f"[{idx}] {article.source} | {article.title}")
            print(f"    URL          : {article.url}")
            print(f"    ê³µê¸‰â†‘(í•˜ë°©)  : {article.supply_bear}")
            print(f"    ìˆ˜ìš”â†“(í•˜ë°©)  : {article.demand_bear}")
            print(f"    ë‹¬ëŸ¬/ê¸ˆë¦¬â†‘   : {article.usd_bear}")
            print(f"    ê³µê¸‰ì°¨ì§ˆ(ìƒë°©): {article.supply_bull}")
            print(f"    ìˆ˜ìš”íšŒë³µ(ìƒë°©): {article.demand_bull}")
            print()
    else:
        print("ê¸°ì‚¬ì—ì„œ ìœ ì˜ë¯¸í•œ í‚¤ì›Œë“œê°€ í¬ì°©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¶”ê°€ ìˆ˜ì§‘ì›ì„ í™•ì¸í•˜ì„¸ìš”.")


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Crude oil sentiment analyzer tuned for DVN actions."
    )
    parser.add_argument(
        "--max-articles",
        type=int,
        default=30,
        help="ë¶„ì„í•  ê¸°ì‚¬ ìµœëŒ€ ê±´ìˆ˜ (ê¸°ë³¸ 30)",
    )
    parser.add_argument(
        "--json",
        action="store_true",
        help="ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì¶œë ¥ (ë¡œê¹…/ìë™í™” ìš©)",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    max_articles = max(5, args.max_articles)

    articles = crawl_news(max_articles)
    market = build_market_snapshot()
    summary = summarize(articles, market)

    if args.json:
        print(json.dumps(summary.to_dict(), ensure_ascii=False, indent=2))
    else:
        render_text(summary)


if __name__ == "__main__":
    main()

